# ğŸ¤– Exercices Machine Learning avec Scikit-Learn

Ce repository contient une sÃ©rie d'exercices pratiques pour apprendre le Machine Learning avec Python et Scikit-Learn.

## ğŸ“š Table des matiÃ¨res

1. [RÃ©gression LinÃ©aire](#1-rÃ©gression-linÃ©aire)
2. [RÃ©gression Logistique](#2-rÃ©gression-logistique)
3. [Clustering K-Means](#3-clustering-k-means)
4. [Comparaison de ModÃ¨les](#4-comparaison-de-modÃ¨les)
5. [Analyse du Churn â€“ TÃ©lÃ©communications](#5.-Analyse-du-Churn---TÃ©lÃ©communications)

---

## ğŸ› ï¸ Installation

### PrÃ©requis

- Python 3.8+
- pip

### Installation des dÃ©pendances

```bash
# CrÃ©er un environnement virtuel
python3 -m venv venv

# Activer l'environnement virtuel
# Sur macOS/Linux :
source venv/bin/activate
# Sur Windows :
venv\Scripts\activate

# Installer les packages nÃ©cessaires
pip install -r requirements.txt
```

---

## 1. RÃ©gression LinÃ©aire

### ğŸ¯ Objectif
PrÃ©dire les prix des logements en Californie en utilisant la rÃ©gression linÃ©aire.

### ğŸ“Š Dataset
- **Source** : California Housing Dataset (Scikit-Learn)
- **Taille** : 20 640 Ã©chantillons
- **Features** : 8 (revenu mÃ©dian, Ã¢ge des maisons, nombre de piÃ¨ces, etc.)
- **Target** : Prix des logements (en centaines de milliers de dollars)

### ğŸ“ Code

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import fetch_california_housing

X, y = fetch_california_housing(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = LinearRegression().fit(X_train, y_train)
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Coefficient RÂ² :", r2)
print("MSE :", mse)
print("Coefficients :", model.coef_)
print("Intercept :", model.intercept_)
```

### ğŸ“ˆ MÃ©triques attendues

- **RÂ² Score** : ~0.60 (60% de variance expliquÃ©e)
- **MSE** : ~0.53
- **RMSE** : ~0.73 (â‰ˆ 73 000$ d'erreur moyenne)

### ğŸ” InterprÃ©tation

- **RÂ² = 0.60** : Le modÃ¨le explique 60% de la variabilitÃ© des prix
- **Coefficients positifs** : Revenu mÃ©dian, nombre de chambres â†’ augmentent le prix
- **Coefficients nÃ©gatifs** : Latitude/Longitude â†’ impact gÃ©ographique

---

## 2. RÃ©gression Logistique

### ğŸ¯ Objectif
Classifier les espÃ¨ces de fleurs Iris (classification multi-classes).

### ğŸ“Š Dataset
- **Source** : Iris Dataset (Scikit-Learn)
- **Taille** : 150 Ã©chantillons
- **Features** : 4 (longueur/largeur des sÃ©pales et pÃ©tales)
- **Classes** : 3 (Setosa, Versicolor, Virginica)

### ğŸ“ Code

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.datasets import load_iris

X, y = load_iris().data, load_iris().target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = LogisticRegression().fit(X_train, y_train)
y_pred = model.predict(X_test)

print("Accuracy :", accuracy_score(y_test, y_pred))
print("Precision :", precision_score(y_test, y_pred, average='macro'))
print("Recall :", recall_score(y_test, y_pred, average='macro'))
print("F1-score :", f1_score(y_test, y_pred, average='macro'))
```

### ğŸ“ˆ MÃ©triques attendues

- **Accuracy** : 1.00 (100%)
- **Precision** : 1.00
- **Recall** : 1.00
- **F1-Score** : 1.00

### ğŸ” Pourquoi un score parfait ?

Le dataset Iris est **linÃ©airement sÃ©parable** :
- Classes bien distinctes
- Features discriminantes
- Dataset simple et propre
- IdÃ©al pour l'apprentissage !

---

## 3. Clustering K-Means

### ğŸ¯ Objectif
Regrouper des donnÃ©es non Ã©tiquetÃ©es en clusters homogÃ¨nes.

### ğŸ“Š Dataset
- **Source** : DonnÃ©es synthÃ©tiques (`make_blobs`)
- **Taille** : 300 Ã©chantillons
- **Features** : 2D (pour visualisation)
- **Clusters** : 7 centres

### ğŸ“ Code

```python
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

X, _ = make_blobs(n_samples=300, centers=7, random_state=42)

# MÃ©thode du coude pour trouver K optimal
inertias = []
for k in range(2, 12):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertias.append(kmeans.inertia_)

# EntraÃ®ner avec K=7
kmeans = KMeans(n_clusters=7, random_state=42)
y_pred = kmeans.fit_predict(X)

# Ã‰valuation
silhouette_avg = silhouette_score(X, y_pred)
print(f"Score de Silhouette : {silhouette_avg:.4f}")

# Visualisation
plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
            s=300, c='red', marker='X', label='Centres')
plt.legend()
plt.show()
```

### ğŸ“ˆ MÃ©triques

| Score de Silhouette | QualitÃ© |
|---------------------|---------|
| 0.7 - 1.0 | âœ… Excellent |
| 0.5 - 0.7 | âœ… Bon |
| 0.25 - 0.5 | âš ï¸ Faible |
| < 0.25 | âŒ Mauvais |

### ğŸ” Techniques utilisÃ©es

- **MÃ©thode du Coude** : Trouver le K optimal via l'inertie
- **Score de Silhouette** : Mesurer la qualitÃ© des clusters
- **Visualisation** : Graphiques des clusters et centres

---

## 4. Comparaison de ModÃ¨les

### ğŸ¯ Objectif
Comparer les performances de 3 modÃ¨les sur la reconnaissance de chiffres manuscrits.

### ğŸ“Š Dataset
- **Source** : Digits Dataset (Scikit-Learn)
- **Taille** : 1 797 images
- **Features** : 64 (images 8Ã—8 pixels)
- **Classes** : 10 (chiffres 0-9)

### ğŸ“ Code

```python
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report

digits = load_digits()
X, y = digits.data, digits.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

models = {
    'Logistic Regression': LogisticRegression(max_iter=10000),
    'SVM': SVC(kernel='rbf'),
    'Random Forest': RandomForestClassifier(n_estimators=100)
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    print(f"\n{name}")
    print(f"Accuracy : {accuracy_score(y_test, y_pred):.4f}")
    print(f"F1-Score : {f1_score(y_test, y_pred, average='macro'):.4f}")
```

### ğŸ“ˆ RÃ©sultats comparatifs

| ModÃ¨le | Accuracy | F1-Score | Vitesse | Avantages |
|--------|----------|----------|---------|-----------|
| **SVM** | ~0.99 | ~0.99 | Moyen | ğŸ¥‡ Meilleure performance |
| **Random Forest** | ~0.97 | ~0.97 | Rapide | âš¡ Bon compromis |
| **Logistic Regression** | ~0.96 | ~0.96 | TrÃ¨s rapide | ğŸš€ Simple et efficace |

### ğŸ” MÃ©triques dÃ©taillÃ©es

- **Accuracy** : Pourcentage de prÃ©dictions correctes
- **Precision** : Parmi les prÃ©dictions positives, combien sont vraies ?
- **Recall** : Parmi les vrais positifs, combien ont Ã©tÃ© dÃ©tectÃ©s ?
- **F1-Score** : Moyenne harmonique (precision + recall)

### ğŸ“Š Visualisations gÃ©nÃ©rÃ©es

1. Exemples d'images (chiffres manuscrits)
2. Distribution des classes
3. Comparaison des 4 mÃ©triques
4. Matrices de confusion (par modÃ¨le)
5. Temps d'exÃ©cution
6. Validation croisÃ©e (5-fold)
7. Classement par F1-Score

---

# 5. Analyse du Churn â€“ TÃ©lÃ©communications

## ğŸ¯ Objectif du Projet

Ce projet vise Ã  rÃ©duire la perte de clients (churn) pour une entreprise de tÃ©lÃ©communications grÃ¢ce Ã  :
- La prÃ©diction des clients Ã  risque
- La segmentation comportementale
- Des recommandations personnalisÃ©es

---

## ğŸ“ Structure du Projet
```txt
telecom-churn-analysis/
â”‚
â”œâ”€â”€ telecom_churn.csv              # Dataset (Ã  fournir)
â”œâ”€â”€ client_lost_telecom.py         # Script principal
â”œâ”€â”€ churn_analysis_results.png     # Visualisations gÃ©nÃ©rÃ©es
â”œâ”€â”€ README.md                      # Ce fichier
â””â”€â”€ requirements.txt               # DÃ©pendances Python
```

---

## ğŸ”§ Installation

    1. Cloner le projet
    git clone https://github.com/thorbeorn/EPSI-M1-Datascience-ML-Exemple-Pratique.git
    cd EPSI-M1-Datascience-ML-Exemple-Pratique

    2. Installer les dÃ©pendances
    pandas>=1.3.0  
    numpy>=1.21.0  
    matplotlib>=3.4.0  
    seaborn>=0.11.0  
    scikit-learn>=1.0.0  

---

## ğŸ“Š Structure des DonnÃ©es
```csv
Colonne	Description
customerID	Identifiant unique du client
tenure	AnciennetÃ©
Contract	Type de contrat
InternetService	Type d'abonnement internet
MonthlyCharges	CoÃ»t mensuel
TotalCharges	CoÃ»t total
Churn	Client parti (Yes/No) â€“ target
```

(+ toutes les autres colonnes du jeu IBM)	

---

## ğŸš€ ExÃ©cution
Lancer lâ€™analyse complÃ¨te :
```bash
python client_lost_telecom/client_lost_telecom.py
```

Le script gÃ©nÃ¨re :
- Rapport de classification
- Score AUC-ROC
- Top 10 features
- RÃ©sultats du clustering
- Recommandations business
- Fichier churn_analysis_results.png (6 graphiques)

## ğŸ§  MÃ©thodes EmployÃ©es
### 1ï¸âƒ£ RÃ©gression Logistique (SupervisÃ©e)
- InterprÃ©table
- ProbabilitÃ©s de churn
- Baseline robuste

- Ã‰valuation :
    - Accuracy, Recall, F1
    - AUC-ROC
    - Matrice de confusion

### 2ï¸âƒ£ K-Means (Non supervisÃ©)
- Segmentation des comportements
- Identification des clusters Ã  risque
- Support des stratÃ©gies de rÃ©tention

- Sorties :
    - MÃ©thode du coude
    - Score de silhouette
    - Taux de churn par cluster

## ğŸ“ˆ RÃ©sultats ClÃ©s Attendus
    - Exemple console :
    ğŸ“Š AUC-ROC: 0.85
    ğŸ” Top features: Contract, tenure, OnlineSecurity...
    âš ï¸ Clients Ã  haut risque: 342

### Graphiques gÃ©nÃ©rÃ©s :
- Courbe ROC
- Matrice de confusion
- Features importantes
- Courbe du coude
- Silhouette
- Taux de churn par cluster

## ğŸ’¡ Recommandations
Actions immÃ©diates
- Contacter les clients avec probabilitÃ© > 70%
- Proposer des offres d'engagement
- AmÃ©liorer les services critiques (TechSupport, OnlineSecurity)

StratÃ©gies par cluster
- Cluster haut risque : actions rapides
- Cluster modÃ©rÃ© : analyse satisfaction
- Cluster loyal : programme fidÃ©litÃ©

---

## ğŸ“– Ressources

### Documentation officielle
- [Scikit-Learn](https://scikit-learn.org/stable/)
- [Pandas](https://pandas.pydata.org/docs/)
- [NumPy](https://numpy.org/doc/)
- [Matplotlib](https://matplotlib.org/stable/contents.html)

### Tutoriels recommandÃ©s
- [Scikit-Learn Tutorial](https://scikit-learn.org/stable/tutorial/index.html)
- [Machine Learning Crash Course (Google)](https://developers.google.com/machine-learning/crash-course)
- [Kaggle Learn](https://www.kaggle.com/learn)

### Datasets pour pratiquer
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [Scikit-Learn Datasets](https://scikit-learn.org/stable/datasets.html)

---

## ğŸ¤ Contribuer

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- ğŸ› Reporter des bugs
- ğŸ’¡ Proposer de nouvelles idÃ©es
- ğŸ“ AmÃ©liorer la documentation
- âœ¨ Ajouter de nouveaux exercices

---

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

---

## âœ¨ Auteur

CrÃ©Ã© avec â¤ï¸ pour apprendre le Machine Learning
